{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "### Show algebraic equivalence between two non-parametric formulations for K-means (objectives $E(S)$ at the bottom of slide 58, Topic 9):\n",
    "### $$  \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k}\\|f_p-f_q\\|^2}{2\\;|S^k|} \\;\\;=\\;\\; const - \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k} \\langle f_p,f_q\\rangle}{|S^k|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof:\n",
    "\n",
    "\\begin{align}\n",
    "LHS &= \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k}\\|f_p-f_q\\|^2}{2\\;|S^k|} \\\\\n",
    "&= \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k}\\langle f_p-f_q, f_p-f_q \\rangle}{2\\;|S^k|} \\\\\n",
    "&= \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k}(\\langle f_p, f_p \\rangle + \\langle f_q, f_q \\rangle - 2 \\langle f_p, f_q \\rangle)}{2\\;|S^k|} \\;\\;\\;\\; \\text{(by properties of inner product)} \\\\\n",
    "&= \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k}(\\|f_p\\|^2 + \\|f_q\\|^2 - 2 \\langle f_p, f_q \\rangle)}{2\\;|S^k|} \\\\\n",
    "&= \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k}(\\|f_p\\|^2 + \\|f_q\\|^2)  - 2 \\sum_{pq\\in S^k}\\langle f_p, f_q \\rangle}{2\\;|S^k|} \\\\\n",
    "\\end{align}\n",
    "\n",
    "Note that $\\sum_{pq\\in S^k}(\\|f_p\\|^2 + \\|f_q\\|^2)$ is just the sum of the square of norms of all pairs of points $(p,q)$. Each point can form $|S^k|$ points with another point (including itself). So the summation is equivalent to $|S^k|\\sum_{p \\in S^k}\\|f_p\\|^2$.\n",
    "\n",
    "Therefore, the above equation becomes\n",
    "\\begin{align}\n",
    "LHS &= \\sum_{k=1}^K \\frac{|S^k| \\sum_{p\\in S^k}\\|f_p\\|^2  - 2 \\sum_{pq\\in S^k}\\langle f_p, f_q \\rangle}{2\\;|S^k|} \\\\\n",
    "&= \\sum_{k=1}^K \\frac{\\sum_{p\\in S^k}\\|f_p\\|^2}{2} - \\frac{2 \\sum_{pq\\in S^k}\\langle f_p, f_q \\rangle}{2\\;|S^k|} \\\\\n",
    "&= \\frac{\\sum_{p\\in S}\\|f_p\\|^2}{2} - \\sum_{k=1}^K \\frac{2 \\sum_{pq\\in S^k}\\langle f_p, f_q \\rangle}{2\\;|S^k|} \\\\\n",
    "&= const - \\sum_{k=1}^K \\frac{\\sum_{pq\\in S^k}\\langle f_p, f_q \\rangle}{\\;|S^k|} \\\\\n",
    "&= RHS\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 (a simple finite-dimensional version of Mercer theorem)\n",
    "### Let $A$ be an $n\\times n$ positive semi-definite matrix defining pairwise affinities between $n$ ponts. Find a closed expression for $n$ vectors $\\phi_i$  (a so-called \"Euclidean embedding\") such that their Euclidean dot products agree with the given affinites, i.e. $\\langle \\phi_i,\\phi_j\\rangle = A_{ij}$ for all $1\\leq i,j\\leq n$. You can assume known eigen-decomposition $A=Q\\Lambda Q^T$ where $Λ=diag(λ_1,…,λ_n)$ is a diagonal matrix of (non-negative!) eigen-values and $Q$ is an orthogonal $n\\times n$ matrix whose columns $Q_i$ are unit eigen-vectors of $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "\n",
    "\\begin{align}\n",
    "A &= Q \\Lambda Q^T \\\\\n",
    "&= [q_1 \\ldots q_n] \\; diag(\\lambda_1, \\ldots, \\lambda_n) \\begin{bmatrix} q_1^T \\\\ \\ldots \\\\ q_n^T \\end{bmatrix} \\\\\n",
    "&= [\\lambda_1q_1 \\ldots \\lambda_nq_n] \\begin{bmatrix} q_1^T \\\\ \\ldots \\\\ q_n^T \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Let $q_{ij}$ denote the $j$-th component of the $i$-th eigenvector $q_i$. Then, multiplying the two matrices gives\n",
    "\n",
    "\\begin{align}\n",
    "A_{ij} &= \\lambda_1 q_{1i}q_{1j} + \\ldots + \\lambda_n q_{ni}q_{nj} \\\\\n",
    "&= \\sqrt{\\lambda_1}q_{1i}\\sqrt{\\lambda_1}q_{1j} + \\ldots \\sqrt{\\lambda_n}q_{ni}\\sqrt{\\lambda_n}q_{nj} \\\\\n",
    "&= \\langle \\phi_i, \\phi_j \\rangle\n",
    "\\end{align}\n",
    "\n",
    "Therefore,\n",
    "\\begin{align}\n",
    "\\phi_i = \\begin{bmatrix} \\sqrt{\\lambda_1}q_{1i} \\\\ \\ldots \\\\ \\sqrt{\\lambda_n}q_{ni} \\end{bmatrix}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 (approximate low-dimenstional Euclidean embedding)\n",
    "### Assume that $\\tilde{A}$ is a low-rank approximation of matrix $A$ in problem 2 of given rank $m<n$. That is, $\\tilde{A} = Q\\Lambda_m Q^T$ where $\\Lambda_m=diag(\\lambda_1,\\dots,\\lambda_m,0,\\dots,0)$ is a diagonal matrix of the largest $m$ eigen values of $A$ (a la Eckart–Young–Mirsky theorem, Topic 8). Using your solution for problem 2, specify a formula for \"Euclidean embedding\" $\\{\\tilde{\\phi}_i\\}$ such that $\\langle \\tilde{\\phi}_i,\\tilde{\\phi}_j\\rangle = \\tilde{A}_{ij}$ and show that  $\\tilde{\\phi}_i \\in {\\cal R}^m$.\n",
    "#### Comment: basic K-means (Lloyd's algorithm) over such points $\\{\\tilde{\\phi}_i\\}$ can be used as an approximate algorithm for kernel clusterng (e.g. for average association criteria). This approach is an example of \"spectral clustering\", which uses eigen decomposition of the affinity matrix $A$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution:\n",
    "\n",
    "\\begin{align}\n",
    "\\tilde{A} = [q_1 \\ldots q_m] \\; diag(\\lambda_1, \\ldots, \\lambda_m) \\begin{bmatrix} q_1^T \\\\ \\ldots \\\\ q_m^T \\end{bmatrix}\n",
    "\\end{align}\n",
    "\n",
    "Following our work in the previous problem, we get\n",
    "$$\n",
    "\\tilde{\\phi}_i = \\begin{bmatrix} \\sqrt{\\lambda_1}q_{1i} \\\\ \\ldots \\\\ \\sqrt{\\lambda_m}q_{mi} \\end{bmatrix} \\in {\\cal R}^m\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 (K-means). \n",
    "### Subproblem 4.1 \n",
    "### Implement K-means algorithm for clustering pixel features. Most of the work is already done for you, but you do get a chance to play with numpy and to evaluate empirical properties of K-means.\n",
    "#### The provided code below only computes random pixel segments. You need to write code producing correct clusters and correct \"means\". To achive this you only need to complete implementation of functions $compute\\_means$ and $compute\\_labels$ inside \"MyKmenasApp\" corresponding to the two iterative steps in Lloyd's algorithm (as in \"compute_k_means_clusters\"). \n",
    "#### Your implementation of the main two steps of K-means algorithm should use RGBXY features. Relative contribution of \"squared errors\" from XY features must be set by parameter \"weightXY\" (or self.w inside MyKmeansApp), so that the squared error between RGBXY feture $F_p=[R_p,G_p,B_p,X_p,Y_p]$ at any pixel $p$ and any given cluster mean $m=[R_m,G_m,B_m,X_m,Y_m]$ is \n",
    "#### $$||F_p - m||^2 = (R_p - R_m)^2 + (G_p - G_m)^2 + (B_p - B_m)^2 + w \\cdot (X_p-X_m)^2 + w \\cdot (Y_p-Y_m)^2.$$\n",
    "#### Fully implemented \"KmeansPresenter\" visulaizes the segmentation results (cluster labels mask) where each cluster is highlighted either by some  random color (press r-key) or by the \"mean\" segment color (press m-key). All keys that \"KmeansPresenter\" responds to are as follows: \n",
    "\n",
    "1. press 'i'-key for each (i)teration of K-means \n",
    "2. press 'c'-key to run K-means to (c)onvergence (when energy improvement is less than given threshold)\n",
    "3. press 'v'-key to run K-means to convergence with (v)isualization of each iteration\n",
    "4. press 'r'-key to start over from (r)andom means\n",
    "5. press 's'-key to change to a random (s)olid color-palette for displaying clusters\n",
    "6. press 't'-key to change to a random (t)ransparent palette for displaying clusters\n",
    "7. press 'm'-key to change to the (m)ean-color palette for displaying clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# loading standard modules\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import img_as_ubyte\n",
    "from skimage.color import rgb2grey\n",
    "\n",
    "# loading custom module (requires file asg1.py in the same directory as the notebook file)\n",
    "from asg1_error_handling import Figure, KmeansPresenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyKmeansApp:\n",
    "\n",
    "    def __init__(self, img, num_clusters=2, weightXY=1.0):\n",
    "        self.k = num_clusters\n",
    "        self.w = weightXY\n",
    "        self.iteration = 0   # iteration counter\n",
    "        self.energy = np.infty  # energy - \"sum of squared errors\" (SSE)\n",
    "\n",
    "        num_rows = self.num_rows = img.shape[0]\n",
    "        num_cols = self.num_cols = img.shape[1]\n",
    "\n",
    "        self.im = img\n",
    "        \n",
    "        self.means = np.zeros((self.k,5),'d') # creates a zero-valued (double) matrix of size Kx5\n",
    "        self.init_means()\n",
    "      \n",
    "        self.no_label = num_clusters  # special label value indicating pixels not in any cluster (e.g. not yet) \n",
    "\n",
    "        # mask \"labels\" where pixels of each \"region\" will have a unique index-label (like 0,1,2,3,..,K-1)\n",
    "        # the default mask value is \"no-label\" (K) implying pixels that do not belong to any region (yet)\n",
    "        self.labels = np.full((num_rows, num_cols), fill_value=self.no_label, dtype=np.int)\n",
    "        \n",
    "        x, y = np.indices((num_rows, num_cols))\n",
    "        self.rgbxy = np.zeros((num_rows, num_cols, 5), dtype=np.int)\n",
    "        self.rgbxy[:,:,:3] = img\n",
    "        self.rgbxy[:,:,3] = x\n",
    "        self.rgbxy[:,:,4] = y\n",
    "        \n",
    "        self.fig = Figure()\n",
    "        self.pres = KmeansPresenter(img, self)\n",
    "        self.pres.connect_figure(self.fig)\n",
    "       \n",
    "    def run(self):\n",
    "        self.fig.show()\n",
    "        \n",
    "    def init_means(self):      \n",
    "        self.iteration = 0           # resets iteration counter \n",
    "        self.energy = np.infty       # and the energy\n",
    "\n",
    "        poolX = range(self.num_cols)\n",
    "        poolY = range(self.num_rows)\n",
    "        \n",
    "        # generate K random pixels (Kx2 array with X,Y coordinates in each row)\n",
    "        random_pixels = np.array([np.random.choice(poolX,self.k),np.random.choice(poolY,self.k)]).T\n",
    "        \n",
    "        for label in range(self.k):\n",
    "            self.means[label,:3] = self.im[random_pixels[label,1],random_pixels[label,0],:3]\n",
    "            self.means[label,3] = random_pixels[label,0]\n",
    "            self.means[label,4] = random_pixels[label,1]\n",
    "    \n",
    "    # This function compute average values for R, G, B, X, Y channel (feature component) at pixels in each cluster\n",
    "    # represented by labels in given mask \"self.labels\" storing indeces in range [0,K). The averages should be\n",
    "    # saved in (Kx5) matrix \"self.means\". The return value should be the number of non-empty clusters. \n",
    "    def compute_means(self):\n",
    "        labels = self.labels\n",
    "        num_clusters = np.zeros((self.k, 1), dtype=np.int)\n",
    "        \n",
    "        # Your code below should compute average values for R,G,B,X,Y features in each segment \n",
    "        # and save them in (Kx5) matrix \"self.means\". For empty clusters set the corresponding mean values \n",
    "        # to infinity (np.infty). Report the correct number of non-empty clusters by the return value.\n",
    "                \n",
    "        for k in range(self.k):\n",
    "            i, j = np.where(labels == k)\n",
    "            num_clusters[k] = i.shape[0]\n",
    "            if num_clusters[k] == 0:\n",
    "                self.means[k,:] = np.infty\n",
    "            else:\n",
    "                k_label_pts = self.im[i, j]\n",
    "                r = k_label_pts[:,0]\n",
    "                g = k_label_pts[:,1]\n",
    "                b = k_label_pts[:,2]\n",
    "                self.means[k,:] = np.array([r.mean(), g.mean(), b.mean(), i.mean(), j.mean()]).astype(np.int)\n",
    "    \n",
    "        return len(num_clusters[num_clusters > 0])\n",
    "            \n",
    "    # The segmentation mask is used by KmeanPresenter to paint segments in distinct colors\n",
    "    # NOTE: valid region labels are in [0,K), but the color map in KmeansPresenter\n",
    "    #       accepts labels in range [0,K] where pixels with no_label=K are not painted/colored.\n",
    "    def get_region_mask(self):  \n",
    "        return self.labels  \n",
    "    \n",
    "    # This function computes optimal (cluster) index/label in range 0,1,...,K-1 for pixel x,y based on \n",
    "    # given current cluster means (self.means). The functions should save these labels in \"self.labels\".\n",
    "    # The return value should be the corresponding optimal SSE.\n",
    "    def compute_labels(self):\n",
    "        shape = (self.num_rows,self.num_cols)\n",
    "        opt_labels = np.full(shape, fill_value=self.no_label, dtype=np.int) # HINT: you can use this array to store and update\n",
    "                                                                            # currently the best label for each pixel.\n",
    "        \n",
    "        min_dist = np.full(shape, fill_value=np.inf)  # HINT: you can use this array to store and update \n",
    "                                                      # the (squared) distance from each pixel to its current \"opt_label\".\n",
    "                                                      # use 'self.w' as a relative weight of sq. errors for X and Y components\n",
    "        \n",
    "        # Replace the code below by your code that computes \"opt_labels\" array of labels in range [0,K) where \n",
    "        # each pixel's label is an index 'i' such that self.mean[i] is the closest to R,G,B,X,Y values of this pixel.\n",
    "        # Your code should also update min_dist so that it contains the optmail squared errors  \n",
    "        \n",
    "        distances = np.full((self.num_rows, self.num_cols, self.k), fill_value=np.inf)\n",
    "                        \n",
    "        for k in range(self.k):\n",
    "            distances[:,:,k] = (((self.rgbxy - self.means[k])**2) * [1, 1, 1, self.w, self.w]).sum(axis=2)\n",
    "\n",
    "        min_dist[:,:] = distances.min(axis=2)\n",
    "        opt_labels[:,:] = distances.argmin(axis=2)\n",
    " \n",
    "        # update the labels based on opt_labels computed above\n",
    "        self.labels = opt_labels\n",
    "        \n",
    "        # returns the optimal SSE (corresponding to optimal clusters/clabels for given means)\n",
    "        return min_dist.sum()\n",
    "            \n",
    "    # The function below is called by \"on_key_down\" in KmeansPresenter\".\n",
    "    # It's goal is to run an iteration of K-means procedure \n",
    "    # updating the means and the (segment) labels \n",
    "    def compute_k_means_clusters(self):  \n",
    "        self.iteration += 1  \n",
    "\n",
    "        # the main two steps of K-means algorithm\n",
    "        energy = self.compute_labels()\n",
    "        num_clusters = self.compute_means()\n",
    "\n",
    "        # computing improvement and printing some information\n",
    "        num_pixels = self.num_rows*self.num_cols\n",
    "        improve_per_pixel = (self.energy - energy)/num_pixels\n",
    "        energy_per_pixel = energy/num_pixels\n",
    "        self.energy = energy\n",
    "        \n",
    "        self.fig.ax.text(0, -8,   # text location  \n",
    "                         'iteration = {:_>2d},  clusters = {:_>2d},  SSE/p = {:_>7.1f},   improve/p = {:_>7.3f}    '.format(\n",
    "                          self.iteration,       num_clusters,        energy_per_pixel,    improve_per_pixel),\n",
    "                          bbox={'facecolor':'white', 'edgecolor':'none'})\n",
    "       \n",
    "        return improve_per_pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subproblem 4.2\n",
    "### Use K-means to generate 3-4 representative results (you can use your own images) with color quantization and superpixels. Experiment with different values of parameter K (in the range 2-80).  Compare representative values of optimal SSE for smaller and larger K and explain the observed differences. Add more cells (code and/or text) as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img = plt.imread('images/rose.bmp')\n",
    "for clusters in [2, 5, 10, 20, 40, 80]:\n",
    "    app = MyKmeansApp(img, num_clusters=clusters, weightXY=2.0)\n",
    "    app.run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subprobelm 4.3\n",
    "### Evaluate sensitivity of K-means to local minima  (you can use your own images). Show 2-3 different solutions for different random initial means and display the corresponding values of the K-means energy. Add more cells (code and/or text) as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = plt.imread('images/tools.bmp')\n",
    "app = MyKmeansApp(img, num_clusters=2, weightXY=0.0)\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
